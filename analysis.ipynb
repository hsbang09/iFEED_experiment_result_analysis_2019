{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'visualization' from '/Users/bang/workspace/iFEED_experiment_result_analysis_2019/visualization.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import scipy.stats as st\n",
    "%matplotlib inline\n",
    "\n",
    "import analyzer as an\n",
    "import visualization as vis\n",
    "importlib.reload(an)\n",
    "importlib.reload(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = '/Users/bang/workspace/iFEED_experiment_result_analysis_2019/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyDataFilePath = os.path.join(rootPath, 'survey.csv')\n",
    "jsonFilesRootPath = os.path.join(rootPath, 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8f92b639c64a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresultAnalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0man\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResultAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurveyDataFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonFilesRootPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/iFEED_experiment_result_analysis_2019/analyzer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, surveyDataFilePath, jsonFilesRootPath, confidenceThreshold)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurveyDataFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurveyDataFilePath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjsonFilesRootPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonFilesRootPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloadDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/iFEED_experiment_result_analysis_2019/analyzer.py\u001b[0m in \u001b[0;36mloadDataSet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty value: column {0} of the participant {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipant_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_self_assessment_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0;31m# Demographic survey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "resultAnalyzer = an.ResultAnalyzer(surveyDataFilePath, jsonFilesRootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultAnalyzer.gradeAnswers(confidenceThreshold=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = resultAnalyzer.subjects[0]\n",
    "s1 = resultAnalyzer.subjects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 5401038285006004819-9_15_19_13 - Fcl: 0.89, Fpwc: 0.56, Dcl: 0.78, Dpwc: 0.56\n"
     ]
    }
   ],
   "source": [
    "s0.printScoreSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: 3700789476005004819-9_16_15_58 - Fcl: 0.22, Fpwc: 0.33, Dcl: 0.67, Dpwc: 0.33\n"
     ]
    }
   ],
   "source": [
    "s1.printScoreSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "[1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "[1, 1, 0, 1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(s0.feature_classification_graded_answers)\n",
    "print(s0.feature_comparison_graded_answers)\n",
    "print(s0.design_classification_graded_answers)\n",
    "print(s0.design_comparison_graded_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 0]\n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(s1.feature_classification_graded_answers)\n",
    "print(s1.feature_comparison_graded_answers)\n",
    "print(s1.design_classification_graded_answers)\n",
    "print(s1.design_comparison_graded_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-30-c985d6ba8f59>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-c985d6ba8f59>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    die here\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "die here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.feature_synthesis_task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = [s0]\n",
    "g2 = [s2]\n",
    "g3 = [s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = visualization.Visualizer([g1,g2,g3], ['r','a','p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.designSynthesisScatter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.grade_feature_questions()/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.confidence_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.grade_design_questions()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.confidence_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.grade_feature_questions()/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.grade_design_questions()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.grade_feature_questions()/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.confidence_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.grade_design_questions()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.confidence_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[0].graded_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[2].graded_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[3].graded_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[0].graded_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[1].graded_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[2].graded_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[2].confidence_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participantId = analyzer.subjects[1].participant_id\n",
    "dirname = '/Users/bang/workspace/iFEED_experiment_result_analysis_2019/data/' + participantId\n",
    "filename = os.path.join(dirname, participantId + \"-design_synthesis.json\")\n",
    "\n",
    "import json\n",
    "with open(filename, newline='') as file:\n",
    "    data = json.loads(file.read())\n",
    "    \n",
    "designs = data['designs_evaluated']\n",
    "\n",
    "designObjective_science = []\n",
    "designObjective_cost = []\n",
    "for i, d in enumerate(designs):\n",
    "    designObjective_science.append(d['outputs'][0])\n",
    "    designObjective_cost.append(d['outputs'][1])\n",
    "\n",
    "x.append(designObjective_science)\n",
    "y.append(designObjective_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(designObjective_science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participantId = analyzer.subjects[2].participant_id\n",
    "dirname = '/Users/bang/workspace/iFEED_experiment_result_analysis_2019/data/' + participantId\n",
    "filename = os.path.join(dirname, participantId + \"-design_synthesis.json\")\n",
    "\n",
    "import json\n",
    "with open(filename, newline='') as file:\n",
    "    data = json.loads(file.read())\n",
    "    \n",
    "designs = data['designs_evaluated']\n",
    "\n",
    "designObjective_science = []\n",
    "designObjective_cost = []\n",
    "for i, d in enumerate(designs):\n",
    "    designObjective_science.append(d['outputs'][0])\n",
    "    designObjective_cost.append(d['outputs'][1])\n",
    "\n",
    "x.append(designObjective_science)\n",
    "y.append(designObjective_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(designObjective_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions = ['interactive', 'manual']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "colors = ['red','green','blue']\n",
    "sizes = [80,80,300]\n",
    "markers = ['o','^','2']\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sc = ax.scatter(\n",
    "               x[i], \n",
    "               y[i], \n",
    "               c=None, \n",
    "               marker=markers[i], \n",
    "               cmap=\"coolwarm\", \n",
    "               label=conditions, \n",
    "               alpha=1.0, \n",
    "               edgecolors='none')\n",
    "\n",
    "ax.legend(conditions)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('Science')\n",
    "ax.set_ylabel('Cost')\n",
    "# plt.colorbar(sc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = analyzer.filterSubjects(pretest_score_threshold=0.5)\n",
    "subjects = None\n",
    "\n",
    "means = []\n",
    "stdevs = []\n",
    "\n",
    "temp = []\n",
    "\n",
    "for i in range(3):    \n",
    "    data = analyzer.getScoreData(subjects=subjects, \n",
    "                                 condition_number=i, \n",
    "                                 exclude_first_task=True, \n",
    "                                 conf_min=0, \n",
    "                                 conf_max=100, \n",
    "                                 time_min=None)\n",
    "    \n",
    "    temp.append(data)\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    stdev = np.std(data)\n",
    "    standardError = stdev / math.sqrt(len(data))\n",
    "    confInterval = st.t.interval(0.95, len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    print(\"condition: {0}, mean: {1}, std: {2}, standardError: {3}\".format(i, mean, stdev, standardError))\n",
    "    \n",
    "    means.append(mean)\n",
    "    stdevs.append(stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(temp[0], temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(means[0], stdevs[0], means[1], stdevs[1], means[2], stdevs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = analyzer.filterSubjects(pretest_score_threshold=0.5)\n",
    "subjects = None\n",
    "\n",
    "means = []\n",
    "stdevs = []\n",
    "\n",
    "for i in range(3):    \n",
    "    data = analyzer.getConfidenceData(subjects=subjects, \n",
    "                                 condition_number=i, \n",
    "                                 exclude_first_task=False)\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    stdev = np.std(data)\n",
    "    standardError = stdev / math.sqrt(len(data))\n",
    "    confInterval = st.t.interval(0.95, len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    print(\"condition: {0}, mean: {1}, std: {2}, standardError: {3}\".format(i, mean, stdev, standardError))\n",
    "    \n",
    "    means.append(mean)\n",
    "    stdevs.append(stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(means[0], stdevs[0], means[1], stdevs[1], means[2], stdevs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Participant Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(analyzer.data)):\n",
    "    dat = analyzer.data[i]\n",
    "    print(\"_______________\")\n",
    "    print(\"key: {0}\".format(dat.key) )\n",
    "    print(\"Pretest: {0}\".format(dat.getScore(problem_type=\"pretest\")))\n",
    "    print(\"DSE: {0}\".format(dat.getScore(condition_number=0)))\n",
    "    print(\"F_bar: {0}\".format(dat.getScore(condition_number=1)))\n",
    "    print(\"F_scatter: {0}\".format(dat.getScore(condition_number=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [[],[],[]]\n",
    "confidences = [[],[],[]]\n",
    "conditions = [[],[],[]]\n",
    "times = [[],[],[]]\n",
    "pretestScores = [[],[],[]]\n",
    "diff = [[],[],[]]\n",
    "\n",
    "for i in range(len(analyzer.data)):\n",
    "    subject = analyzer.data[i]\n",
    "    \n",
    "    for j in range(3):\n",
    "        score = subject.getScore(condition_number=j)\n",
    "        confidence = subject.getConfidence(condition_number=j)\n",
    "        time = subject.getTime(condition_number=j)\n",
    "        pretestScore = subject.getScore(problem_type=\"pretest\")\n",
    "        scoreDiff = score - pretestScore\n",
    "        \n",
    "        scores[j].append(score)\n",
    "        confidences[j].append(np.mean(confidence))\n",
    "        times[j].append(np.mean(time))\n",
    "        pretestScores[j].append(pretestScore)\n",
    "        diff[j].append(scoreDiff)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "colors = ['red','green','blue']\n",
    "sizes = [80,80,300]\n",
    "markers = ['o','^','2']\n",
    "\n",
    "for i, condition in enumerate(['DSE', 'FSE_bar', 'FSE_scatter']):\n",
    "    #ax.scatter(scores[i], confidences[i], s=sizes[i], c=colors[i], marker=markers[i], label=condition, alpha=0.6, edgecolors='none')\n",
    "\n",
    "    sc = ax.scatter(scores[i], \n",
    "               times[i], \n",
    "               s=sizes[i], \n",
    "               c=None, \n",
    "               marker=markers[i], \n",
    "               cmap=\"coolwarm\", \n",
    "               label=condition, \n",
    "               alpha=1.0, \n",
    "               edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('Mean score')\n",
    "ax.set_ylabel('Mean time')\n",
    "# plt.colorbar(sc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(diff[0], diff[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(diff[0], diff[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(diff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(diff[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScatter(x1, x2, x3):\n",
    "    plt.scatter(x1,x2, s=None, c=x3, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarGraph(mean1, stdev1, mean2, stdev2, mean3=None, stdev3=None):\n",
    "    \n",
    "    if mean3 is not None:\n",
    "        N = 3\n",
    "        means = (mean1, mean2, mean3)\n",
    "        stdevs = (stdev1, stdev2, stdev3)\n",
    "    \n",
    "    else:\n",
    "        N = 2\n",
    "        means = (mean1, mean2)\n",
    "        stdevs = (stdev1, stdev2)\n",
    "        \n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.35       # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind, means, width, color='skyblue', yerr=stdevs)\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('Scores')\n",
    "    \n",
    "    if mean3 is not None:\n",
    "        ax.set_xticks(ind + width / 3)\n",
    "        ax.set_xticklabels(('1', '2', '3'))\n",
    "        \n",
    "    else:\n",
    "        ax.set_xticks(ind + width / 2)\n",
    "        ax.set_xticklabels(('1', '2'))\n",
    "\n",
    "    #ax.legend((rects1[0], rects2[0]), ('Men', 'Women'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotECDF(scores1,scores2):\n",
    "    \n",
    "    import statsmodels.api as sm # recommended import according to the docs\n",
    "\n",
    "    sample = scores1\n",
    "    ecdf = sm.distributions.ECDF(scores1)\n",
    "    x = np.linspace(min(sample), max(sample))\n",
    "    y = ecdf(x)\n",
    "    plt.step(x, y)\n",
    "\n",
    "    sample2 = scores2\n",
    "    ecdf = sm.distributions.ECDF(sample2)\n",
    "    x = np.linspace(min(sample2), max(sample2))\n",
    "    y = ecdf(x)\n",
    "    plt.step(x, y)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToFile(data, header ,filePath = \"/Users/bang/workspace/iFEED-experiment-201711-result/data/data.csv\"):\n",
    "    with open(filePath, 'w') as f:\n",
    "        f.write(header + \"\\n\")\n",
    "        for row in data:\n",
    "            f.write(\",\".join(row) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = analyzer.results\n",
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m1,m2,s1,s2 = analyzer.printStatistics(subjects)\n",
    "plotBarGraph(m1,s1,m2,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,f2 = analyzer.getScoreData(subjects)\n",
    "data = [[str(x),str(y)] for x,y in zip(f1,f2)]\n",
    "writeToFile(data, header=\"First condition, Second condition\")\n",
    "plotECDF(f1,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(analyzer.first_condition_scores,bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analyzer.second_condition_scores,bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
