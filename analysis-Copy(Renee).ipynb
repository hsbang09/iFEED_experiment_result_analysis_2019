{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'visualization' from 'C:\\\\Users\\\\renee\\\\Documents\\\\GitHub\\\\iFEED_experiment_result_analysis_2019\\\\visualization.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import scipy.stats as st\n",
    "%matplotlib inline\n",
    "\n",
    "import analyzer \n",
    "import subject\n",
    "import visualization\n",
    "importlib.reload(analyzer)\n",
    "importlib.reload(subject)\n",
    "importlib.reload(visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = 'C:\\\\Users\\\\renee\\\\Documents\\\\GitHub\\\\iFEED_experiment_result_analysis_2019\\\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyDataFilePath = os.path.join(rootPath, 'survey.csv')\n",
    "jsonFilesRootPath = os.path.join(rootPath, 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultAnalyzer = analyzer.ResultAnalyzer(surveyDataFilePath, jsonFilesRootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = resultAnalyzer.subjects[0]\n",
    "s1 = resultAnalyzer.subjects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 33,\n",
       " 'gender': 2,\n",
       " 'education': 7,\n",
       " 'major': 'Aerospace Engineering, Industrial / Systems Engineering',\n",
       " 'employerType': 'Non-profit (non-profit research organization, government contractor, etc.)'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0.demographic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 34,\n",
       " 'gender': 1,\n",
       " 'education': 7,\n",
       " 'major': 'Aerospace Engineering',\n",
       " 'employerType': 'Academic institution'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.demographic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorDemographicString(argument): \n",
    "    switcher = {  \n",
    "        1: \"Aerospace Engineering\", \n",
    "        2: \"Biological / Agricultural / Biomedial Engineering\", \n",
    "        3: \"Chemical Engineering\",\n",
    "        4: \"Civil / Environmental Engineering\",\n",
    "        5: \"Computer Science / Information Science\",\n",
    "        6: \"Electrical Engineering\",\n",
    "        7: \"Industrial / Systems Engineering\",\n",
    "        8: \"Mechanical Engineering\",\n",
    "        9: \"Mathematics / Statistics\",\n",
    "        10: \"Physics\",\n",
    "        11: \"Chemistry\",\n",
    "        12: \"Biological Science\",\n",
    "        13: \"Other\",\n",
    "    } \n",
    "\n",
    "    return switcher.get(argument, \"nothing\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Major=s0.demographic_data['major']\n",
    "print(Major[1])\n",
    "Major2=Major.split(',')\n",
    "print(Major2)\n",
    "MajorIntList=[int(i) for i in Major2]\n",
    "print(MajorIntList)\n",
    "type(MajorIntList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MajorStringList=MajorIntList\n",
    "for w in range(len(MajorIntList)):\n",
    "    print(w)\n",
    "    MajorStringList[w]=majorDemographicString(MajorIntList[w]) \n",
    "print(MajorStringList)\n",
    "concatMajor=', '.join(MajorStringList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.demographic_data['major']=concatMajor\n",
    "s0.demographic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subjects=resultAnalyzer.subjects\n",
    "majorArray=[1,2]\n",
    "print(majorArray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in majorArray:\n",
    "    majorTest=majorDemographicString(majorArray[i-1])\n",
    "    print(majorTest)\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def employerTypeDemographicString(argument): \n",
    "    switcher = {  \n",
    "        1: \"For profit\", \n",
    "        2: \"Non-profit (non-profit research organization, government contractor, etc.)\", \n",
    "        3: \"Government\",\n",
    "        4: \"Academic institution\",\n",
    "        5: \"Other\",\n",
    "    } \n",
    "\n",
    "    return switcher.get(argument, \"nothing\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employerTest=employerTypeDemographicString(1)\n",
    "print(employerTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.printScoreSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.printScoreSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//END TESTING ZONE FOR RENEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s0.feature_synthesis_task_data['features_found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1.feature_classification_graded_answers)\n",
    "print(s1.feature_comparison_graded_answers)\n",
    "print(s1.design_classification_graded_answers)\n",
    "print(s1.design_comparison_graded_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s0.feature_classification_graded_answers)\n",
    "print(s0.feature_comparison_graded_answers)\n",
    "print(s0.design_classification_graded_answers)\n",
    "print(s0.design_comparison_graded_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s0.design_synthesis_task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "die here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.feature_synthesis_task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = [s0]\n",
    "g2 = [s2]\n",
    "g3 = [s3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = visualization.Visualizer([g1,g2,g3], ['r','a','p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.designSynthesisScatter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.grade_feature_questions()/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.confidence_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.grade_design_questions()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0.confidence_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.grade_feature_questions()/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.grade_design_questions()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.grade_feature_questions()/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.confidence_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.grade_design_questions()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.confidence_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[0].graded_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[2].graded_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[3].graded_feature_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[0].graded_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[1].graded_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[2].graded_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.subjects[2].confidence_design_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participantId = analyzer.subjects[1].participant_id\n",
    "dirname = '/Users/bang/workspace/iFEED_experiment_result_analysis_2019/data/' + participantId\n",
    "filename = os.path.join(dirname, participantId + \"-design_synthesis.json\")\n",
    "\n",
    "import json\n",
    "with open(filename, newline='') as file:\n",
    "    data = json.loads(file.read())\n",
    "    \n",
    "designs = data['designs_evaluated']\n",
    "\n",
    "designObjective_science = []\n",
    "designObjective_cost = []\n",
    "for i, d in enumerate(designs):\n",
    "    designObjective_science.append(d['outputs'][0])\n",
    "    designObjective_cost.append(d['outputs'][1])\n",
    "\n",
    "x.append(designObjective_science)\n",
    "y.append(designObjective_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(designObjective_science)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participantId = analyzer.subjects[2].participant_id\n",
    "dirname = '/Users/bang/workspace/iFEED_experiment_result_analysis_2019/data/' + participantId\n",
    "filename = os.path.join(dirname, participantId + \"-design_synthesis.json\")\n",
    "\n",
    "import json\n",
    "with open(filename, newline='') as file:\n",
    "    data = json.loads(file.read())\n",
    "    \n",
    "designs = data['designs_evaluated']\n",
    "\n",
    "designObjective_science = []\n",
    "designObjective_cost = []\n",
    "for i, d in enumerate(designs):\n",
    "    designObjective_science.append(d['outputs'][0])\n",
    "    designObjective_cost.append(d['outputs'][1])\n",
    "\n",
    "x.append(designObjective_science)\n",
    "y.append(designObjective_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(designObjective_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions = ['interactive', 'manual']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "colors = ['red','green','blue']\n",
    "sizes = [80,80,300]\n",
    "markers = ['o','^','2']\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    sc = ax.scatter(\n",
    "               x[i], \n",
    "               y[i], \n",
    "               c=None, \n",
    "               marker=markers[i], \n",
    "               cmap=\"coolwarm\", \n",
    "               label=conditions, \n",
    "               alpha=1.0, \n",
    "               edgecolors='none')\n",
    "\n",
    "ax.legend(conditions)\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('Science')\n",
    "ax.set_ylabel('Cost')\n",
    "# plt.colorbar(sc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = analyzer.filterSubjects(pretest_score_threshold=0.5)\n",
    "subjects = None\n",
    "\n",
    "means = []\n",
    "stdevs = []\n",
    "\n",
    "temp = []\n",
    "\n",
    "for i in range(3):    \n",
    "    data = analyzer.getScoreData(subjects=subjects, \n",
    "                                 condition_number=i, \n",
    "                                 exclude_first_task=True, \n",
    "                                 conf_min=0, \n",
    "                                 conf_max=100, \n",
    "                                 time_min=None)\n",
    "    \n",
    "    temp.append(data)\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    stdev = np.std(data)\n",
    "    standardError = stdev / math.sqrt(len(data))\n",
    "    confInterval = st.t.interval(0.95, len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    print(\"condition: {0}, mean: {1}, std: {2}, standardError: {3}\".format(i, mean, stdev, standardError))\n",
    "    \n",
    "    means.append(mean)\n",
    "    stdevs.append(stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(temp[0], temp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(means[0], stdevs[0], means[1], stdevs[1], means[2], stdevs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = analyzer.filterSubjects(pretest_score_threshold=0.5)\n",
    "subjects = None\n",
    "\n",
    "means = []\n",
    "stdevs = []\n",
    "\n",
    "for i in range(3):    \n",
    "    data = analyzer.getConfidenceData(subjects=subjects, \n",
    "                                 condition_number=i, \n",
    "                                 exclude_first_task=False)\n",
    "\n",
    "    mean = np.mean(data)\n",
    "    stdev = np.std(data)\n",
    "    standardError = stdev / math.sqrt(len(data))\n",
    "    confInterval = st.t.interval(0.95, len(data)-1, loc=np.mean(data), scale=st.sem(data))\n",
    "    print(\"condition: {0}, mean: {1}, std: {2}, standardError: {3}\".format(i, mean, stdev, standardError))\n",
    "    \n",
    "    means.append(mean)\n",
    "    stdevs.append(stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotBarGraph(means[0], stdevs[0], means[1], stdevs[1], means[2], stdevs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Participant Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(analyzer.data)):\n",
    "    dat = analyzer.data[i]\n",
    "    print(\"_______________\")\n",
    "    print(\"key: {0}\".format(dat.key) )\n",
    "    print(\"Pretest: {0}\".format(dat.getScore(problem_type=\"pretest\")))\n",
    "    print(\"DSE: {0}\".format(dat.getScore(condition_number=0)))\n",
    "    print(\"F_bar: {0}\".format(dat.getScore(condition_number=1)))\n",
    "    print(\"F_scatter: {0}\".format(dat.getScore(condition_number=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [[],[],[]]\n",
    "confidences = [[],[],[]]\n",
    "conditions = [[],[],[]]\n",
    "times = [[],[],[]]\n",
    "pretestScores = [[],[],[]]\n",
    "diff = [[],[],[]]\n",
    "\n",
    "for i in range(len(analyzer.data)):\n",
    "    subject = analyzer.data[i]\n",
    "    \n",
    "    for j in range(3):\n",
    "        score = subject.getScore(condition_number=j)\n",
    "        confidence = subject.getConfidence(condition_number=j)\n",
    "        time = subject.getTime(condition_number=j)\n",
    "        pretestScore = subject.getScore(problem_type=\"pretest\")\n",
    "        scoreDiff = score - pretestScore\n",
    "        \n",
    "        scores[j].append(score)\n",
    "        confidences[j].append(np.mean(confidence))\n",
    "        times[j].append(np.mean(time))\n",
    "        pretestScores[j].append(pretestScore)\n",
    "        diff[j].append(scoreDiff)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "colors = ['red','green','blue']\n",
    "sizes = [80,80,300]\n",
    "markers = ['o','^','2']\n",
    "\n",
    "for i, condition in enumerate(['DSE', 'FSE_bar', 'FSE_scatter']):\n",
    "    #ax.scatter(scores[i], confidences[i], s=sizes[i], c=colors[i], marker=markers[i], label=condition, alpha=0.6, edgecolors='none')\n",
    "\n",
    "    sc = ax.scatter(scores[i], \n",
    "               times[i], \n",
    "               s=sizes[i], \n",
    "               c=None, \n",
    "               marker=markers[i], \n",
    "               cmap=\"coolwarm\", \n",
    "               label=condition, \n",
    "               alpha=1.0, \n",
    "               edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "ax.set_xlabel('Mean score')\n",
    "ax.set_ylabel('Mean time')\n",
    "# plt.colorbar(sc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(diff[0], diff[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_ind(diff[0], diff[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(diff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(diff[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScatter(x1, x2, x3):\n",
    "    plt.scatter(x1,x2, s=None, c=x3, alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBarGraph(mean1, stdev1, mean2, stdev2, mean3=None, stdev3=None):\n",
    "    \n",
    "    if mean3 is not None:\n",
    "        N = 3\n",
    "        means = (mean1, mean2, mean3)\n",
    "        stdevs = (stdev1, stdev2, stdev3)\n",
    "    \n",
    "    else:\n",
    "        N = 2\n",
    "        means = (mean1, mean2)\n",
    "        stdevs = (stdev1, stdev2)\n",
    "        \n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.35       # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(ind, means, width, color='skyblue', yerr=stdevs)\n",
    "\n",
    "    # add some text for labels, title and axes ticks\n",
    "    ax.set_ylabel('Scores')\n",
    "    ax.set_title('Scores')\n",
    "    \n",
    "    if mean3 is not None:\n",
    "        ax.set_xticks(ind + width / 3)\n",
    "        ax.set_xticklabels(('1', '2', '3'))\n",
    "        \n",
    "    else:\n",
    "        ax.set_xticks(ind + width / 2)\n",
    "        ax.set_xticklabels(('1', '2'))\n",
    "\n",
    "    #ax.legend((rects1[0], rects2[0]), ('Men', 'Women'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotECDF(scores1,scores2):\n",
    "    \n",
    "    import statsmodels.api as sm # recommended import according to the docs\n",
    "\n",
    "    sample = scores1\n",
    "    ecdf = sm.distributions.ECDF(scores1)\n",
    "    x = np.linspace(min(sample), max(sample))\n",
    "    y = ecdf(x)\n",
    "    plt.step(x, y)\n",
    "\n",
    "    sample2 = scores2\n",
    "    ecdf = sm.distributions.ECDF(sample2)\n",
    "    x = np.linspace(min(sample2), max(sample2))\n",
    "    y = ecdf(x)\n",
    "    plt.step(x, y)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToFile(data, header ,filePath = \"/Users/bang/workspace/iFEED-experiment-201711-result/data/data.csv\"):\n",
    "    with open(filePath, 'w') as f:\n",
    "        f.write(header + \"\\n\")\n",
    "        for row in data:\n",
    "            f.write(\",\".join(row) + \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = analyzer.results\n",
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m1,m2,s1,s2 = analyzer.printStatistics(subjects)\n",
    "plotBarGraph(m1,s1,m2,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,f2 = analyzer.getScoreData(subjects)\n",
    "data = [[str(x),str(y)] for x,y in zip(f1,f2)]\n",
    "writeToFile(data, header=\"First condition, Second condition\")\n",
    "plotECDF(f1,f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(analyzer.first_condition_scores,bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(analyzer.second_condition_scores,bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
